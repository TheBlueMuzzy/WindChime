---
phase: 03-audio-engine
plan: 01
type: execute
---

<objective>
Create the useAudioEngine hook — AudioContext setup, audio buffer loading, and single sound playback function.

Purpose: Establish the audio foundation that all subsequent sound features build on. This hook encapsulates Web Audio API complexity behind a simple API.
Output: A reusable React hook that can load audio files and play them on demand.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

# Prior phase context (from dependency graph):
@.planning/phases/02-qr-scanner/02-03-SUMMARY.md

# Key source files:
@src/App.tsx
@src/components/QrScanner.tsx

**Tech stack available:** Vite 7.3.1, React 19, TypeScript, @yudiel/react-qr-scanner, barcode-detector, @vitejs/plugin-basic-ssl
**Established patterns:** Inline styles, dvh/dvw viewport, Scanner wrapper component, useRef for non-render state, timeout-based auto-clear

**Constraining decisions:**
- Web Audio API for playback (not `<audio>` tags) — need precise layering, gain control, fade envelopes
- Sounds bundled with app — pre-load on startup, files in public/ directory
- 3 cards for v1 — but architecture should support more

**Approach notes:**
- Web Audio API: Create AudioContext, use fetch + decodeAudioData to load buffers, AudioBufferSourceNode for playback
- AudioContext must be created in "suspended" state on mobile — resumed on user gesture (handled in plan 03-03)
- Buffer loading should happen once on mount, not per-play
- Use a Map<string, AudioBuffer> to store decoded buffers by sound ID
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create useAudioEngine hook with AudioContext and buffer loading</name>
  <files>src/hooks/useAudioEngine.ts</files>
  <action>
Create a new hook `useAudioEngine` that:

1. Creates an AudioContext on first call (use `useRef` to persist across renders — do NOT create in state)
2. Exposes a `loadSound(id: string, url: string): Promise<void>` function that:
   - Fetches the audio file from the URL
   - Decodes it with `audioContext.decodeAudioData()`
   - Stores the resulting AudioBuffer in a `Map<string, AudioBuffer>` ref
3. Exposes a `playSound(id: string): void` function that:
   - Looks up the buffer by id
   - Creates a new AudioBufferSourceNode
   - Connects it to audioContext.destination
   - Calls `.start(0)` to play immediately
   - If buffer not found, logs a warning (don't throw)
4. Exposes `isReady: boolean` state (true when AudioContext exists)
5. Return type: `{ loadSound, playSound, isReady }`

Keep it simple — no gain nodes yet (Phase 6), no fade (Phase 6), no concurrent tracking (Phase 7). Just load and play.

AudioContext constructor: use `new (window.AudioContext || (window as any).webkitAudioContext)()` for Safari compatibility.
  </action>
  <verify>
TypeScript compiles: `npx tsc --noEmit` passes with no errors related to useAudioEngine.
  </verify>
  <done>
Hook file exists at src/hooks/useAudioEngine.ts. Exports loadSound, playSound, and isReady. TypeScript compiles clean.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add a test sound file and verify playback works</name>
  <files>public/sounds/test-tone.mp3, src/App.tsx</files>
  <action>
1. Create a placeholder test sound:
   - Use a simple approach: create a short sine wave tone as an MP3 or WAV file in `public/sounds/`
   - If generating is complex, create a minimal valid WAV file programmatically (a 0.5s 440Hz sine wave) using a Node script, or download a tiny free-use tone from a CDN
   - Alternative: just create the directory and note that a real sound file is needed (Phase 4 handles actual sounds)

2. Wire up useAudioEngine in App.tsx temporarily:
   - Import and call `useAudioEngine()`
   - In a `useEffect`, call `loadSound('test', '/sounds/test-tone.mp3')` (only if a real file exists)
   - In the onScan callback, after setting lastDetected, call `playSound('test')` — this makes any QR detection trigger the test sound
   - This is a temporary integration to prove the hook works — Plan 03-02 does the proper mapping

3. If no real audio file can be generated easily, skip the App.tsx wiring and just ensure the hook compiles and the `public/sounds/` directory exists. The verification in 03-02 will confirm actual playback.
  </action>
  <verify>
`npx tsc --noEmit` passes. `public/sounds/` directory exists. If test sound was added: open app in browser, scan a QR code, hear the test tone.
  </verify>
  <done>
public/sounds/ directory created. useAudioEngine hook compiles. If test sound available: QR detection triggers audible playback.
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npx tsc --noEmit` passes with no errors
- [ ] `npm run build` succeeds
- [ ] src/hooks/useAudioEngine.ts exists and exports { loadSound, playSound, isReady }
- [ ] public/sounds/ directory exists
</verification>

<success_criteria>

- useAudioEngine hook created with clean TypeScript types
- AudioContext creation and buffer loading/decoding implemented
- playSound function creates source node and plays buffer
- Build passes with no errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-audio-engine/03-01-SUMMARY.md`
</output>
