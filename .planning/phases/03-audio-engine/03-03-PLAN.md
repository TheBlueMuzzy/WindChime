---
phase: 03-audio-engine
plan: 03
type: execute
---

<objective>
Handle mobile audio unlock — iOS and Android require a user gesture before AudioContext can produce sound.

Purpose: Without this, the app appears broken on mobile — QR codes detect but no sound plays. This is the #1 mobile Web Audio API gotcha.
Output: Audio works reliably on first QR detection on both iOS Safari and Android Chrome.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-audio-engine/03-01-SUMMARY.md
@.planning/phases/03-audio-engine/03-02-SUMMARY.md

# Key source files:
@src/App.tsx
@src/hooks/useAudioEngine.ts
@src/config/sounds.ts

**Constraining decisions:**
- Must work on iOS Safari 14.5+ and Android Chrome 88+
- No native app install — browser only
- Camera permission already grants a user gesture context on some browsers, but NOT all

**Mobile Audio Context rules:**
- AudioContext starts in "suspended" state on mobile browsers
- Must call `audioContext.resume()` inside a user gesture event handler (touchstart, click, pointerdown)
- iOS Safari is strictest — even `touchstart` sometimes doesn't count unless it's a direct response to a tap
- Best pattern: Show a "Tap to start" overlay, resume AudioContext on tap, then hide overlay
- After resume, all subsequent playback works without gesture requirement
- Some Android Chrome versions auto-resume if camera permission was just granted — but don't rely on this
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add AudioContext resume to useAudioEngine</name>
  <files>src/hooks/useAudioEngine.ts</files>
  <action>
1. Add a `resume(): Promise<void>` function to useAudioEngine that:
   - Calls `audioContext.resume()` if context state is 'suspended'
   - Returns immediately if already 'running'
   - Expose `contextState: AudioContextState` ('suspended' | 'running' | 'closed') as a returned value — use state so UI can react to changes

2. Add a `state` listener on AudioContext:
   - Listen to `audioContext.onstatechange` to update the contextState reactively
   - This way UI knows when audio is ready

3. Update `playSound` to:
   - Check if context is suspended — if so, attempt resume() before playing
   - This is a fallback — the primary unlock happens via the tap overlay (Task 2)

Return type becomes: `{ loadSound, playSound, resume, isReady, contextState }`
  </action>
  <verify>
`npx tsc --noEmit` passes. useAudioEngine exports resume and contextState.
  </verify>
  <done>
resume() function exposed. contextState tracked reactively. playSound attempts resume as fallback.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add "Tap to start" unlock overlay in App.tsx</name>
  <files>src/App.tsx</files>
  <action>
1. Add state: `audioUnlocked` (boolean, starts false)

2. When `contextState === 'suspended'` AND `cameraStatus === 'active'`:
   - Show a semi-transparent overlay on top of the camera feed
   - Centered text: "Tap anywhere to enable sound"
   - Style: dark overlay (rgba(0,0,0,0.7)), white text, large enough to tap easily
   - The overlay covers the entire camera container

3. On tap/touch of the overlay:
   - Call `resume()` from useAudioEngine
   - Set `audioUnlocked = true`
   - Overlay disappears

4. If `contextState` is already 'running' (some Android browsers auto-resume):
   - Set `audioUnlocked = true` automatically (no overlay needed)
   - Use a useEffect watching contextState

5. Don't show the overlay while camera is loading — only after camera is active but audio is suspended.

Keep it simple — the overlay is a single div with an onClick/onTouchStart. Inline styles consistent with existing app style.
  </action>
  <verify>
`npx tsc --noEmit` passes. `npm run build` succeeds. On mobile: overlay appears after camera starts, tap dismisses it, subsequent QR detections produce sound.
  </verify>
  <done>
Tap-to-start overlay shows when audio is suspended. Tapping resumes AudioContext and hides overlay. Sound plays on subsequent QR detections.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Mobile audio unlock flow — tap overlay that enables Web Audio playback on iOS/Android</what-built>
  <how-to-verify>
    1. Run: `npm run dev` (HTTPS dev server)
    2. On your phone, open the HTTPS URL
    3. Confirm: After camera activates, you see "Tap anywhere to enable sound" overlay
    4. Tap the overlay — it should disappear
    5. Display a QR code encoding "chime-1" on another screen
    6. Point phone at QR code — confirm you hear the test tone
    7. If on iOS Safari: force-close browser, reopen URL, verify the flow works from scratch
    8. Confirm: No sound plays BEFORE tapping the overlay (AudioContext is suspended)
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe issues to fix</resume-signal>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `npx tsc --noEmit` passes
- [ ] `npm run build` succeeds
- [ ] AudioContext resume exposed in useAudioEngine
- [ ] Tap overlay appears on mobile when audio is suspended
- [ ] Tapping unlocks audio — subsequent QR detections play sound
- [ ] Works on iOS Safari (strictest audio policy)
</verification>

<success_criteria>

- Mobile audio unlock works reliably on iOS Safari and Android Chrome
- User sees clear "tap to start" prompt
- After unlock, QR → sound flow works without further interaction
- Phase 3 complete: Audio Engine Core fully functional
</success_criteria>

<output>
After completion, create `.planning/phases/03-audio-engine/03-03-SUMMARY.md`

This is the final plan in Phase 3. Summary should note:
- Phase 3 complete
- Audio engine: create context, load buffers, play sounds, mobile unlock
- Ready for Phase 4: Test Content (actual wind chime sounds + QR code generation)
</output>
